# Conductor + Claude Code Hook FAQ

작성일: 2026-02-24  
대상: 비개발자/운영자 관점에서 Conductor 오케스트레이션, 스킬, 에이전트, 훅 이해

## Q0. 오케스트레이션은 실제로 어떻게 하나요?
A. Conductor에서는 "2레벨 오케스트레이션"으로 이해하면 가장 쉽습니다.

Level 1: 사람이 워크스페이스를 조율(수동)
- 기능별로 워크스페이스를 나눕니다. 예: 로그인, 대시보드, 결제
- 각 워크스페이스는 독립 브랜치/독립 에이전트로 병렬 작업합니다.
- 사람은 Diff Viewer와 PR로 결과를 확인/머지합니다.

Level 2: 에이전트가 서브에이전트를 조율(자동)
- 한 워크스페이스 안에서 메인 에이전트가 "감독" 역할을 맡습니다.
- `.claude/commands/orchestrate.md` 같은 슬래시 커맨드(스킬)로 작업을 분해하고 전문가를 호출합니다.
- 예: DB → Backend/Frontend 병렬 → Test 순서로 진행

핵심 원칙:
- 오케스트레이터는 코드를 직접 쓰기보다 `분해(Decompose) → 배정(Dispatch) → 검증(Verify)`에 집중
- 독립 작업은 병렬, 의존 작업은 순차로 배치

## Q0-1. 오케스트레이터는 어떻게 만들고 쓰나요?
A. 최소 구성은 아래 3단계입니다.

1. 오케스트레이터 커맨드 파일 생성
- 위치: `.claude/commands/orchestrate.md`
- 내용: 작업 분석, 계획(Plan), 실행(Task), 검증 흐름 정의

2. 전문가 에이전트 준비
- 위치: `.claude/agents/*.md`
- 예: `frontend-specialist`, `backend-specialist`, `database-specialist`, `test-specialist`

3. 채팅에서 실행
- `/orchestrate 사용자 프로필 페이지 구현`
- 메인 에이전트가 작업을 쪼개어 전문가에게 자동 위임

## Q0-2. 서브에이전트에게 일을 잘 시키려면?
A. 지시문 품질이 결과 품질을 좌우합니다.

좋은 지시문에 포함할 것:
- 정확한 파일 경로
- 참고할 기존 파일/패턴
- 입출력 스펙(API 응답 형태 등)
- 스타일/컴포넌트 재사용 규칙
- 라우팅/테스트/검증 조건

한 줄 요약:
- "프로필 만들어줘"보다
- "어느 파일에, 어떤 패턴으로, 무엇을 검증해 완료할지"를 명확히 전달해야 합니다.

## Q0-3. 가장 강력한 운영 패턴은?
A. Level 1 + Level 2를 함께 쓰는 방식입니다.

- 워크스페이스 단위로 큰 기능을 분리(Conductor 레벨)
- 각 워크스페이스 내부에서 `/orchestrate`로 전문가 병렬 분업(Claude Code 레벨)

결과:
- 기능 간 충돌은 줄고
- 기능 내부 개발 속도는 빨라지며
- 검증 루프까지 자동화하기 쉬워집니다.

## Q1. Conductor에 최적화된 하네스를 만들 때, hook 기능도 쓸 수 있나요?
A. 네, 가능합니다. 다만 구분이 필요합니다.

- Conductor 자체 문서 기준으로는 별도의 "Conductor Hook API"보다는 `setup/run/archive` 스크립트와 워크스페이스 오케스트레이션이 중심입니다.
- 사용자가 말한 hook이 **Claude Code hooks**라면, Conductor에서 Claude Code를 실행할 때 그대로 활용할 수 있습니다.

정리하면:
- Conductor 바깥 오케스트레이션: 워크스페이스/브랜치/병렬 실행 관리
- Claude Code 내부 제어: hooks로 이벤트 기반 정책/검수 자동화

## Q2. "내가 말한 hook은 클로드 코드 hook"이라면 답이 달라지나요?
A. 네. 이 경우 답은 "사용 가능"이 명확합니다.

- hook 설정 파일(`~/.claude/settings.json`, `.claude/settings.json`, `.claude/settings.local.json`)을 통해 동작시킬 수 있습니다.
- `/hooks` 관련 설정 흐름도 Claude Code 환경에서 동일하게 적용됩니다.
- Conductor의 Codex 탭과는 별개 기능입니다. 즉, **Claude Code를 쓸 때의 hook**입니다.

## Q3. hook을 비개발자 눈높이로 한 문장으로 설명하면?
A. "에이전트가 특정 순간마다 반드시 통과해야 하는 자동 심사 규칙"입니다.

비유:
- 오케스트레이션: 지휘자
- 서브에이전트: 연주자
- 훅: 무대 안전요원/품질감독

## Q4. 오케스트레이션, 서브에이전트, hook은 서로 어떻게 상호작용하나요?
A. 역할 분리가 핵심입니다.

- 오케스트레이션: 누가 어떤 일을 언제 할지 배분
- 서브에이전트: 배정된 일을 실제 수행
- hook: 수행 과정과 완료 시점을 자동 검사/차단/승인

실제 상호작용:
- `PreToolUse`: 위험 명령 사전 차단
- `PostToolUse`: 변경 직후 빠른 품질 점검
- `TaskCompleted`: 완료 처리 직전 품질 게이트
- `TeammateIdle`: 팀원이 쉬기 직전 미완료/품질 미달 확인

## Q5. 인간 개입 없이 자율적으로 팀이 일하게 만들 수 있나요?
A. 가능합니다. 다만 "완전 무인화"는 품질/안전 정책 설계가 먼저입니다.

필수 조건:
- 위험 작업 차단 규칙(안전 훅)
- 완료 기준(Definition of Done) 명문화
- 완료 직전 강제 검수(품질 훅)
- 팀 유휴 전 잔여 작업 확인(팀 훅)

## Q6. 비개발자용 3단계 무인 하네스 템플릿은 무엇인가요?
A. 아래 3개를 순서대로 깔면 됩니다.

1. 안전 훅(Safety Gate)
- 목적: 사고 예방
- 대표 이벤트: `PreToolUse`, `PermissionRequest`
- 기능: 위험 명령/민감 경로 수정 차단

2. 품질 훅(Quality Gate)
- 목적: 동작하는 결과만 통과
- 대표 이벤트: `PostToolUse`, `Stop`
- 기능: 테스트/린트/체크리스트 검증

3. 팀 훅(Team Gate)
- 목적: 팀 단위 완료 기준 강제
- 대표 이벤트: `TaskCompleted`, `TeammateIdle`
- 기능: 품질 미달이면 완료/idle 차단

## Q7. 자율화된 에이전트 팀의 "작업 결과 품질 검수 로직"은 어떻게 설계하나요?
A. 아래 5단계 파이프라인이 실무적으로 가장 안정적입니다.

1. Task별 완료 기준(DoD) 정의
- 테스트 통과
- 린트 통과
- 변경 요약
- 리스크/롤백 포인트 기록

2. 작업 중간 자동 검사
- 코드 변경 이벤트에서 빠른 검사 실행
- 결과를 공용 상태 파일(예: `.context/quality/*.json`)에 저장

3. `TaskCompleted` 강제 게이트
- 완료 직전에 테스트/린트/문서화 상태 재확인
- 실패 시 구체적 피드백 후 `exit 2`로 완료 차단

4. `TeammateIdle` 강제 게이트
- 유휴 전, 본인 미해결 작업/품질 실패 여부 점검
- 미충족 시 `exit 2`로 idle 차단

5. 리드 에이전트 재지시 루프
- "무엇이 실패했고, 다음에 무엇을 할지 1개 액션"만 명확히 재할당
- 반복하여 사람 개입 없이 품질 루프를 닫음

## Q8. 운영 시 주의할 점은?
A. 아래 4가지는 꼭 지켜야 합니다.

- 훅 스크립트는 짧고 재실행 안전(idempotent)하게 작성
- `Stop` 훅은 무한 루프 방지 조건 포함
- `async` 훅은 차단이 아니라 알림/비동기 검사 용도
- 훅은 사용자 권한으로 실행되므로 보안 규칙을 먼저 설계

## Q9. 지금 바로 적용할 최소 체크리스트는?
A. 다음 6개만 먼저 하세요.

- `.claude/settings.json`에 hook 기본 골격 추가
- `PreToolUse` 안전 차단 스크립트 1개
- `TaskCompleted` 품질 게이트 스크립트 1개
- `TeammateIdle` 잔여 작업 점검 스크립트 1개
- `.context/quality/` 상태 파일 규약 정의
- 실패 메시지 포맷 통일(누가 봐도 다음 액션이 보이게)

## Q10. 상태전이 규칙(FSM)은 왜 중요한가요?
A. "지금 팀이 어느 단계인지"를 명확히 해서 무한 반복과 조기 종료를 막아줍니다.

쉽게 말하면:
- 상태(State): 분석, 구현, 검증, PR 같은 현재 단계
- 전이(Transition): 어떤 조건이 되면 다음 단계로 이동하는 규칙

없으면 생기는 문제:
- 누가 봐도 끝난 것 같은데 실제 완료 기준은 미달
- 실패했는데 다음 단계로 넘어가서 나중에 큰 재작업 발생
- 같은 검증 루프를 끝없이 반복

핵심 원칙:
- 각 상태마다 `진입조건/종료조건/타임아웃/다음 상태`를 문서로 고정
- 실패 유형별 `롤백 상태`를 미리 정해 자동 복구

## Q11. "LangGraph 에이전트"는 오케스트레이션인가요?
A. 대부분은 맞습니다. 정확히는 "LangGraph는 오케스트레이션 엔진"에 가깝습니다.

- 강점: 라우팅, 상태전이, 재시도, 루프 제어, 중단-재개
- 결론: 상위 레이어(지휘/흐름 제어)에 가장 적합

## Q12. 마이크로 에이전트 전략이면 LangGraph 워커도 꼭 만들어야 하나요?
A. 보통은 아닙니다. 시작은 아래 구조가 가장 효율적입니다.

- 상위: LangGraph 오케스트레이터 1개
- 하위: 마이크로 워커(작은 CLI/함수/API 작업 단위)
- 예외: 워커 내부가 복잡한 다단계 판단/루프일 때만 해당 워커를 서브그래프로 승격

한 줄 결론:
- "모든 워커를 그래프로 만들기"보다
- "오케스트레이션만 그래프로 만들고 워커는 작게 유지"가 초기 품질/속도에 유리합니다.

---

## 상세 설명판 (Long Form)

아래는 위 FAQ의 요약 답변을 바탕으로, 실제 운영 관점에서 "왜 그렇게 하는지"까지 풀어 쓴 상세 버전입니다.

### 1) Conductor에서 오케스트레이션을 이해하는 가장 쉬운 틀

Conductor는 기본적으로 "워크스페이스 단위 병렬 실행기"이고, Claude Code는 "워크스페이스 안에서 실제 작업을 수행하는 에이전트"입니다.

비유:
- Conductor: 여러 팀을 배치하는 프로젝트 매니저
- Workspace: 팀별 독립 작업실
- Claude Code 에이전트: 각 작업실의 실무 담당자
- Hook/CI: 작업 품질을 검사하는 자동 심사 시스템

핵심 구조:
1. Conductor 레벨(바깥): 워크스페이스를 기능 단위로 분리
2. Claude Code 레벨(안): 오케스트레이터가 서브에이전트에 작업 배정
3. 품질 레벨: Hook + CI + PR 리뷰로 검증

### 2) Git/PR/브랜치/Worktree를 비개발자 관점으로 이해하기

#### 2-1. 레포지토리(Repository)
- 결과물이 모이는 중심 저장소입니다.
- 회사에서는 보통 GitHub Organization(회사 계정) 아래 여러 레포를 둡니다.
- iOS 앱 코드베이스는 레포 1개인 경우가 흔하지만, 회사 전체는 보통 다중 레포 구조입니다.

#### 2-2. 브랜치(Branch)
- "작업 줄기"입니다.
- `main`은 기준 줄기, 기능 개발은 별도 브랜치에서 진행합니다.

#### 2-3. Worktree
- 같은 레포를 브랜치별로 동시에 열어 작업할 수 있게 해주는 Git 기능입니다.
- Conductor 워크스페이스는 사실상 이 worktree 구조를 쉽게 쓰게 만든 형태입니다.

#### 2-4. Diff Viewer
- "무엇이 바뀌었는지"를 줄 단위로 비교하는 화면입니다.
- 작업 완료 전에 반드시 Diff로 변경 의도와 실수를 확인합니다.

#### 2-5. Push와 PR
- Push: 내 로컬 브랜치 변경(커밋)을 원격(GitHub)으로 업로드
- PR(Pull Request): "이 브랜치를 main에 합쳐도 되는지" 검토 요청

실무에서 자주 하는 표현:
- 엄밀히는 "브랜치를 push"가 맞습니다.
- 다만 "PR에 푸시했다"라고도 자주 말하며, 이는 PR 연결 브랜치가 업데이트됐다는 뜻입니다.

### 3) 워크스페이스 상태(Backlog/In Progress/In Review/Done/Canceled)와 Archive

상태는 팀 운영의 가시화를 위한 라벨입니다. 제품 버전/설정에 따라 세부 동작은 다를 수 있지만, 운영 의미는 다음처럼 보면 됩니다.

1. Backlog
- 아직 본격 실행 전
- 할 일 목록은 있으나 작업이 시작되지 않은 상태

2. In Progress
- 구현/수정이 실제로 진행 중인 상태

3. In Review
- PR 리뷰나 검수 단계에 진입한 상태

4. Done
- 머지/동기화 기준으로 완료 처리된 상태
- 일부는 시스템 조건 충족 시 자동으로 Done 전환될 수 있음

5. Canceled
- 중단/폐기된 작업 상태
- 팀 규칙이나 운영 플로우에 따라 수동/자동 처리 기준이 다를 수 있음

#### Archive와 Done의 차이
- Done: "작업 완료 상태"
- Archive: "워크스페이스 보관 액션"

Archive의 의미:
- 작업실을 정리해 목록에서 내려놓는 것
- 필요할 때 복원 가능
- 아카이브 시 `archive script`가 실행되도록 구성 가능

### 4) CI(테스트/린트/빌드)와 AI 검수의 관계

CI는 자동 품질 게이트입니다.

1. 테스트(Test)
- 기능이 요구사항대로 동작하는지 확인

2. 린트(Lint)
- 코드 규칙 위반/잠재 오류 패턴 검사

3. 빌드(Build)
- 실제 배포 가능한 형태로 컴파일/패키징 가능한지 확인

중요한 운영 원칙:
- CI는 "기계적으로 검증 가능한 품질"을 담당
- AI 리뷰는 "의미/설계/일관성/리스크"를 담당
- 둘을 순서대로 붙여야 품질이 올라갑니다

### 5) Hook(Claude Code)과 자율 오케스트레이션의 상호작용

Hook은 이벤트 시점 자동 규칙입니다.

자주 쓰는 이벤트:
1. PreToolUse
- 위험한 명령을 실행 전에 차단

2. PostToolUse
- 수정 직후 빠른 점검 실행

3. TaskCompleted
- 작업 완료 처리 직전 강제 검수

4. TeammateIdle
- 팀원이 유휴 상태로 빠지기 전 미해결 작업 점검

자율 운영에서 Hook 역할:
- "아무나 끝냈다고 말하면 끝나는" 구조를 막음
- 완료 기준 미달 시 자동으로 루프 재진입

### 6) 고품질 자율 에이전트팀의 핵심 루프

가장 안정적인 기본 루프:
1. 오케스트레이터가 작업 분해
2. 워커 에이전트가 구현
3. CI 실행
4. 리뷰 에이전트 평가
5. 실패 시 수정 후 재검증
6. 통과 시 PR 생성
7. 머지 후 아카이브
8. SOT 분석 결과를 다음 규칙에 반영

이때 품질을 결정하는 4축:
- 라우팅 정확도
- 상태전이 규칙
- 품질 게이트 강도
- 실패 로그(SOT) 기반 규칙 업데이트 속도

### 7) SOT와 실행 규칙 분리 원칙

운영 난이도가 올라갈수록 반드시 분리해야 합니다.

1. SOT(Source of Truth)
- 무엇이 실패했고 왜 실패했는지 기록하는 로그 저장소
- 예: `.context/sot/daily-log.md`, `incidents.md`, `metrics.md`

2. 실행 규칙
- 에이전트가 실제 작업할 때 따르는 기준
- 예: `CLAUDE.md`, `.claude/agents/*.md`, `.claude/commands/*.md`, hook 설정

핵심:
- SOT는 "원인 분석 자료"
- 실행 규칙은 "행동 지침"
- SOT에서 발견한 실패 패턴을 실행 규칙으로 승격해야 같은 실수를 줄일 수 있음

### 8) 마이크로 에이전트 전략 검증 (대분류 에이전트 vs 세분화 에이전트)

질문하신 가설은 타당합니다.

왜 유리한가:
1. 역할이 좁을수록 판단 기준이 명확
2. 출력 포맷과 품질 기준을 고정하기 쉬움
3. 오케스트레이터의 배정 정책을 정교화하기 쉬움

실패하는 경우:
- 역할이 너무 잘게 쪼개져 호출 오버헤드가 커질 때
- 라우팅 기준이 약해서 오배정이 반복될 때
- 상태전이 규칙 없이 무한 루프가 생길 때

권장:
- 처음엔 6~12개 수준으로 시작
- 오배정률/재작업률/KPI 개선이 확인될 때만 확장

### 9) LangChain을 지금부터 쓰고 싶을 때의 현실적인 시작점

바로 시작해도 됩니다. 다만 단계적으로 가는 게 안정적입니다.

#### 9-1. Router와 Handoff 차이
1. Router
- "어느 전문가에게 보낼지" 분류/분배
- 초기 진입 라우팅에 강함

2. Handoff
- "누가 다음 턴을 주도할지" 대화 주도권 전환
- 순차 워크플로우(분석→구현→검수)에 강함

#### 9-2. 운영 패턴
1. 첫 진입은 Router
2. 단계 전환은 Handoff
3. 최종 통과는 CI + 리뷰 게이트

#### 9-3. LangGraph는 언제?
- 상태 분기/재시도/중단-재개/HITL이 복잡해질 때
- 초기에는 LangChain 패턴으로 충분한 경우가 많음

### 10) MCP는 꼭 필요한가? 로컬 MCP는 괜찮은가?

#### 10-1. 꼭 필요한가?
- 초기에는 필수 아님
- CLI로 충분히 해결 가능하면 MCP 도입을 늦춰도 됨

#### 10-2. 로컬 MCP는 괜찮은가?
- 네, 충분히 괜찮음
- 다만 토큰 사용량은 "로컬/원격"보다 "응답 payload 크기"에 더 크게 좌우됨

#### 10-3. 토큰 최적화 규칙
1. 요약 우선, 상세는 2차 조회
2. 필드 최소화
3. 페이지네이션/limit 기본 적용
4. 캐시와 중복 호출 억제

### 11) Conductor 기반 하네스 실전 도입 순서 (비개발자용)

1주차:
1. 기본 템플릿 생성
- `CLAUDE.md`
- `.claude/commands/orchestrate.md`
- `.claude/agents/*`
- `conductor.json`
- `.context/sot/*`

2. 샌드박스 워크스페이스 1개 운영 시작

2주차:
1. Hook 안전/품질 게이트 적용
2. CI 파이프라인 연결
3. 실패 케이스를 SOT에 누적

3주차:
1. 라우팅 규칙 튜닝
2. 상태전이 규칙 문서화
3. 반복 상한/에스컬레이션 규칙 확정

4주차:
1. GitHub 브랜치 보호 규칙 강화
2. 고위험 변경 인간 승인 프로세스 고정
3. KPI 기반 개선 루프 정착

### 12) KPI(성과 지표) 없으면 자율화는 실패한다

최소 5개는 숫자로 관리하세요.

1. 라우팅 정확도(오배정률)
2. CI 1회 통과율
3. 평균 재작업 횟수
4. PR 머지까지 리드타임
5. 머지 후 결함 유출률

기준:
- 에이전트를 늘리기 전에 KPI 개선이 있는지 확인
- 개선 없으면 분화가 아니라 규칙/게이트/라우팅을 먼저 수정

### 13) 상태전이 규칙(FSM)을 비개발자도 운영 가능한 방식으로 설계하기

FSM은 어렵게 들리지만 본질은 단순합니다.
"팀이 어디에 있고, 무엇을 만족하면 다음으로 가는지"를 표로 고정하는 방법입니다.

#### 13-1. 왜 필요한가
상태전이 규칙이 없으면 다음 두 가지가 반복됩니다.
1. 무한 루프: 검증 실패 후 같은 행동을 계속 반복
2. 조기 종료: 핵심 검증을 건너뛰고 Done 처리

#### 13-2. 최소 상태 모델(권장)
작게 시작하면 운영이 쉽습니다.
1. Analyze(분석)
2. Implement(구현)
3. Verify(검증)
4. PR(검토 요청)
5. Merge/Done(완료)

#### 13-3. 상태 정의 표(템플릿)

| 상태 | 진입 조건 | 종료 조건 | 타임아웃 | 성공 시 다음 | 실패 시 롤백 |
|---|---|---|---|---|---|
| Analyze | 작업 목표/범위 입력 완료 | 작업 계획 + 완료 기준(DoD) 확정 | 30분 | Implement | 요구사항 불명확 시 Analyze 유지 |
| Implement | 계획과 대상 파일 확정 | 코드/문서 변경 + 자체 체크 통과 | 2시간 | Verify | 설계 충돌 시 Analyze |
| Verify | 변경사항 존재 | 테스트/린트/체크리스트 통과 | 45분 | PR | 실패 유형별 Implement 또는 Analyze |
| PR | 검증 통과 증적 확보 | PR 생성 + 변경 요약 + 리스크 명시 | 30분 | Merge/Done | 증적 누락 시 Verify |
| Merge/Done | 리뷰 승인/머지 완료 | 상태 기록 및 아카이브 규칙 반영 | 15분 | 종료 | 머지 실패 시 PR |

#### 13-4. 실패 유형별 롤백 규칙(핵심)
실패를 한 종류로 묶으면 복구가 느려집니다. 최소 3개로 분리하세요.
1. 테스트 실패: Implement로 롤백
2. 요구사항 오해: Analyze로 롤백
3. 품질 문서/증적 누락: Verify로 롤백

이렇게 하면 "어디로 돌아가야 하는지"를 팀이 매번 다시 토론하지 않아도 됩니다.

#### 13-5. 타임아웃과 에스컬레이션
자율팀은 "시간 제한"이 없으면 멈춘 듯 계속 돈다고 느껴집니다.

권장 규칙:
1. 상태별 최대 반복 횟수 지정(예: Verify 최대 3회)
2. 초과 시 자동 에스컬레이션(리드 에이전트 또는 사람 리뷰)
3. 에스컬레이션 메시지 형식 고정

예:
- 실패 원인 1줄
- 시도 횟수
- 다음 권장 액션 1개

#### 13-6. Hook/오케스트레이션과 결합
FSM은 문서만으로 끝내지 말고 자동 이벤트에 연결해야 합니다.
1. `TaskCompleted` 훅: Verify/PR 종료 조건 강제
2. `TeammateIdle` 훅: 미충족 상태에서 idle 차단
3. 오케스트레이터: 실패 유형 분류 후 롤백 상태로 재배정

운영 관점 결론:
- FSM은 "통제"가 아니라 "자동화 품질을 안정화하는 레일"입니다.

### 14) LangGraph + 마이크로 에이전트 팀의 현실적인 권장 아키텍처

질문하신 방향은 맞습니다.
다만 "모든 것을 그래프로"보다 "그래프는 지휘, 워커는 작게"가 더 실용적입니다.

#### 14-1. 권장 구조
1. Orchestrator(LangGraph)
- 라우팅, 상태전이, 재시도, 품질 게이트 호출 담당

2. Micro Workers(비-그래프)
- 보안 검사 워커
- 신규 기술 적용 워커
- 보수적 안정화 워커
- 테스트 강화 워커

3. Reviewer/Evaluator
- 산출물 점수화(정확성, 안정성, 유지보수성)
- 임계치 미달 시 수정 루프 재진입

#### 14-2. 언제 워커를 LangGraph로 승격할까
아래 조건이 2개 이상이면 승격을 고려하세요.
1. 워커 내부 단계가 3단계 이상
2. 외부 도구 호출이 다수이며 실패 복구 규칙이 복잡
3. 장기 상태(체크포인트) 보존 필요
4. HITL(인간 승인) 분기가 자주 필요

그 외에는 단일 워커로 유지하는 편이 운영비용이 낮습니다.

#### 14-3. Router vs Handoff 재정리
1. Router: 처음에 "누가 맡을지" 배정
2. Handoff: 진행 중 "주도권을 누구에게 넘길지" 전환

실무 패턴:
- 진입은 Router
- 단계 전환은 Handoff
- 종료는 Verify/PR 게이트

#### 14-4. 품질이 실제로 올라가는 최소 루프
1. Orchestrator가 작업 분해 및 워커 배정
2. 워커 실행 후 즉시 빠른 검증
3. Reviewer가 점수화 및 실패 원인 분류
4. 롤백 규칙으로 이전 상태 복귀
5. 기준 점수 이상일 때만 PR 상태 진입

핵심:
- 모델 크기보다 "루프 품질"이 결과 품질을 더 크게 좌우합니다.
---

## 참고 링크
- https://code.claude.com/docs/en/hooks
- https://code.claude.com/docs/en/hooks-guide
- https://code.claude.com/docs/en/sub-agents
- https://code.claude.com/docs/en/agent-teams
- https://code.claude.com/docs/en/skills
- https://docs.conductor.build/core/checkpoints
- https://docs.conductor.build/workflow
- https://docs.conductor.build/core/scripts
- https://docs.conductor.build/core/conductor-json
- https://docs.conductor.build/core/todos
- https://docs.langchain.com/oss/python/langchain/multi-agent/index
- https://docs.langchain.com/oss/python/langchain/multi-agent/router
- https://docs.langchain.com/oss/python/langchain/multi-agent/handoffs
- https://docs.langchain.com/oss/python/langchain/multi-agent/subagents
- https://www.anthropic.com/research/building-effective-agents/
